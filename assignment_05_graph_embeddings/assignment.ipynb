{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8329b6f4",
   "metadata": {},
   "source": [
    "# Assignment — Graph embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.cluster import k_means\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642ffad",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bb674",
   "metadata": {
    "id": "FZvmCa1k_nK-"
   },
   "source": [
    "In this assignment, we will evaluate node embedding methods on the facebook graph where nodes are pages and edges are links. Each node has a category: government, tv-show, company, politician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b808f10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-I2DhszTyVg3",
    "outputId": "19e0d089-5d3e-4e22-8671-ea29cd0ee92f"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/netspractice/network-science/main/datasets/musae_facebook_ego_802.gml'\n",
    "open('musae_facebook_ego_802.gml', 'wb').write(requests.get(url).content)\n",
    "G = nx.read_gml('musae_facebook_ego_802.gml')\n",
    "G = nx.convert_node_labels_to_integers(G)\n",
    "_labels = np.array(list(nx.get_node_attributes(G, 'value').values()))\n",
    "unique = list(set(_labels))\n",
    "labels = np.array([unique.index(l) for l in _labels])\n",
    "len(G), labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec0a8e",
   "metadata": {},
   "source": [
    "### Task 1. DeepWalk (0 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c4ef43",
   "metadata": {
    "id": "VFEVAy9NmX1_"
   },
   "source": [
    "Deepwalk is an approach for learning latent representations of nodes in a network. The motivation of DeepWalk is based on an observation that the frequency of nodes occurrence in the short random walks in social networks is similar to the frequency of words occurrence in sentences in natural languages.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/netspractice/network-science/main/images/node_word_powerlaw.png\" width=600>\n",
    "\n",
    "The both follow a power-law distribution, therefore NLP word embedding models can help to represent nodes in networks. DeepWalk is based on SkipGram model that is trained to predict the context for a given word.\n",
    "\n",
    "<img src='https://lena-voita.github.io/resources/lectures/word_emb/w2v/window_prob1-min.png' width=600>\n",
    "\n",
    "(an image is taken from [NLP Course For You](https://lena-voita.github.io/nlp_course.html))\n",
    "\n",
    "DeepWalk uses nodes instead of words and random walks on a network instead of sentences. Let a central word be a start node of a random walk, context words be nodes in a tail of a random walk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625249cd",
   "metadata": {
    "id": "GNEIjHkD2Ess"
   },
   "source": [
    "Write a function `sample_random_walks` that takes a graph, number of walks per node and the length of walks, returns np.array of the shape (total number of walks) x (length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12c005",
   "metadata": {
    "deletable": false,
    "id": "9Ow1aAoq0N1V",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3ce58f440fdc8e196671a9575dd819b",
     "grade": false,
     "grade_id": "cell-6dae7ab8bdd8bca1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sample_random_walks(G, walks_per_node, length):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5049f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "140ad69a04c642eebaed28a48c43c178",
      "0347a2a554574d57bd58b3cffbcf02d7",
      "a45fe0effeb14e0b9c65183329c85264",
      "c6d5b6e134f648da91d36226f7f35fd2",
      "858baf0e1f6c4dd58376cfad45f05b1d",
      "2b5df2606fc3442cb31ab7285c24e231",
      "7bc21924dbf2464784969d251c607146",
      "6caf612d17bb49acbd8312a29822f47f",
      "5a4b2899237741fcaebe44b8f082256b",
      "4ca75fe814e84d97894c9e6cbfc1fa10",
      "977bbb206542425da429a0d0d3b8c33c"
     ]
    },
    "deletable": false,
    "editable": false,
    "id": "ium8TB601-Ea",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf580c164d7ab96868a44d09bf855390",
     "grade": true,
     "grade_id": "cell-6804ce30d354612f",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "bcec441e-3970-450f-9776-9df9055a8fe6"
   },
   "outputs": [],
   "source": [
    "walks_per_node = 5\n",
    "length = 5\n",
    "rwalks = sample_random_walks(G, walks_per_node, length)\n",
    "assert rwalks.shape == (len(G) * walks_per_node, length)\n",
    "assert np.all(rwalks[:, 0][::5] == np.arange(len(G)))\n",
    "A = nx.to_numpy_array(G)\n",
    "assert np.all(A[rwalks[0, :-1], rwalks[0, 1:]] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24cade",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECHOTLkSbmaO",
    "outputId": "a4d8f720-0287-4790-a9b5-b1dd37f022bf"
   },
   "outputs": [],
   "source": [
    "rwalks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9c586",
   "metadata": {
    "id": "FZH3kd2Tvvfh"
   },
   "source": [
    "Consider a graph $G=(V,E)$. Let the first node in each random walk be _start node_ and others be _context nodes_. DeepWalk uses two embedding layers:\n",
    "* $v_i: \\{0, 1\\}^{|V|} \\to \\mathbb R^{d}$ embeds the one-hot encoded vector of the start node $i$ to latent space\n",
    "* $u_j: \\{0, 1\\}^{|V|} \\to \\mathbb R^{d}$ embeds the one-hot encoded vector of the context node $j$ to latent space\n",
    "\n",
    "The objective is to maximize the probability that $i$ and $j$ co-occur on a random walk over the network. Maximizing of the probability is equivalent to minimizing negative log-likelihood:\n",
    "\n",
    "$$\\mathcal L = - \\frac{1}{|V|\\times N} \\sum_{i=1}^{|V|\\times N} \\sum_{j=1}^L \\log P(j|i)$$\n",
    "\n",
    "where $N$ is the number of walks per node, $L$ is the length of a random walk excluding start node. $P(j|i)$ can be modelled by softmax with dot product similarity score $\\text{sim}(i, j) = u_i^\\top v_j$ as follows:\n",
    "\n",
    "$$\\mathcal L = - \\frac{1}{|V|\\times N} \\sum_{i=1}^{|V|\\times N} \\sum_{j=1}^L \\log \\frac{\\exp(v_i^\\top u_j)}{\\sum_{k=1}^{|V|}\\exp(u_k^\\top v_i)}$$\n",
    "\n",
    "However, calculating $\\sum_{k=1}^{|V|}\\exp(v_i^\\top u_j)$ is computationally expensive in a large network. To overcome such an obstacle, we can approximate softmax by binary cross-entropy with _negative sampling_. Instead of calculating softmax, we draw some random (negative) context and minimize binary cross-entropy using sigmoid function:\n",
    "\n",
    "$$\\mathcal L^{\\text{pos}}_{ij} = -\\log P(j|i) = - \\log \\sigma(v_i^\\top u_j) \\\\\n",
    "\\mathcal L^\\text{neg}_{ij} = -\\sum_{k=1}^K \\log P(k|i) = -\\sum_{k=1}^K \\log (1 - \\sigma(v_i^\\top u_k)) \\\\ \n",
    "\\mathcal L = \\frac{1}{|V|\\times N} \\sum_{i=1}^{|V|\\times N} \\sum_{j=1}^L \\left(\\mathcal L^{\\text{pos}}_{ij} + \\mathcal L^\\text{neg}_{ij}\\right)$$\n",
    "\n",
    "where $K$ is the number of negative nodes for each context node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6721a",
   "metadata": {
    "id": "WWO3FS8f2BXA"
   },
   "source": [
    "Let us create a dataset for computing a such loss function. Write a class `NodeContextDataset`. \n",
    "\n",
    "Function `__init__` takes random walks, the number of nodes in a graph and the number of negative nodes per each context node.\n",
    "\n",
    "Function `__len__` returns the number of random walks.\n",
    "\n",
    "Function `__getitem__` takes an index of random walk, sample a negative context and returns a tuple:\n",
    "\n",
    "* start node, torch.int64\n",
    "* positive context nodes, torch.tensor of the shape (number of context nodes)\n",
    "* negative context nodes, torch.tensor of the shape (number of context nodes, number of negative nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b442d89",
   "metadata": {
    "deletable": false,
    "id": "65SsWhyu2SZd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f37ac528f7f9c27b886cd738c11ed47f",
     "grade": false,
     "grade_id": "cell-92d80df6a92f6fc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NodeContextDataset(Dataset):\n",
    "    def __init__(self, rwalks, n_nodes, n_neg):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c07942",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "me3MM4yK4NSb",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33e459957a271d9fbd1451657741be76",
     "grade": true,
     "grade_id": "cell-a745361ad8b8827a",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = NodeContextDataset(rwalks, len(G), n_neg=5)\n",
    "assert len(dataset) == rwalks.shape[0]\n",
    "start_node, pos_context, neg_context0 = dataset[0]\n",
    "start_node, pos_context, neg_context1 = dataset[0]\n",
    "assert start_node == 0\n",
    "assert start_node.dtype == torch.int64\n",
    "assert start_node.shape == ()\n",
    "assert pos_context.shape == (4, )\n",
    "assert neg_context0.shape == neg_context1.shape ==(4, 5)\n",
    "assert not torch.all(neg_context0 == neg_context1)\n",
    "dloader = DataLoader(dataset, batch_size=2)\n",
    "for start_nodes, pos_context, neg_context in dloader:\n",
    "    break\n",
    "assert start_nodes.shape == (2,)\n",
    "assert pos_context.shape == (2, 4)\n",
    "assert neg_context.shape == (2, 4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903fd2b9",
   "metadata": {
    "id": "XPaJWYeEOyH9"
   },
   "source": [
    "Write a function `cross_entropy` that takes vectors $v$, positive $u$, negative $u$ and returns the binary cross-entropy loss before reduction $\\frac{1}{|V|\\times N} \\sum_{i=1}^{|V|\\times N} \\sum_{j=1}^L$.\n",
    "\n",
    "_Remark: to prevent $-\\infty$ in log, add $\\varepsilon=1^{-6}$ as follows `torch.log(x + 1e-6)`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cda82",
   "metadata": {
    "deletable": false,
    "id": "Gc4yYrdtTysM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c52f1255915a57c9e9e136063d7a1bb",
     "grade": false,
     "grade_id": "cell-e2f4ba57342fd5e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy(v, u_pos, u_neg):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bc928",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5cJcyDIqaUTL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6560bbf935e37888e3e3b1bf47bd0881",
     "grade": true,
     "grade_id": "cell-588d17c4193a2d02",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "start_node_emb = torch.randn(len(G), 16)\n",
    "context_emb = torch.randn(len(G), 16)\n",
    "v = start_node_emb[start_nodes]\n",
    "u_pos = context_emb[pos_context]\n",
    "u_neg = context_emb[neg_context]\n",
    "loss = cross_entropy(v, u_pos, u_neg)\n",
    "assert loss.shape == (2, 4)\n",
    "lpos = -torch.log(torch.sigmoid(v[0] @ u_pos[0, 0]) + 1e-6)\n",
    "lneg = -torch.log(1 - torch.sigmoid(torch.tensor([v[0] @ u_neg[0, 0, i] for i in range(5)])) + 1e-6).sum()\n",
    "assert round((lpos + lneg).item(), 2) == round(loss[0, 0].item(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71769b5c",
   "metadata": {
    "id": "gH1kaJd4Sccq"
   },
   "source": [
    "Here is SkipGram model with negative sampling. It takes start nodes and positive, negative context nodes, returns cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadaebee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_nAOYIwr8_ZQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc264bd4d5ca49b71b8ebd673adcb1d7",
     "grade": false,
     "grade_id": "cell-79e82ef853f9c439",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class SkipGramNegativeSampling(nn.Module):\n",
    "    def __init__(self, n_nodes, dim):\n",
    "        super().__init__()\n",
    "        self.start_node_emb = nn.Embedding(n_nodes, dim)\n",
    "        self.context_emb = nn.Embedding(n_nodes, dim)\n",
    "    def forward(self, start_nodes, pos_context, neg_context):\n",
    "        v = self.start_node_emb(start_nodes)\n",
    "        u_pos = self.context_emb(pos_context)\n",
    "        u_neg = self.context_emb(neg_context)\n",
    "        return cross_entropy(v, u_pos, u_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834f8a1",
   "metadata": {
    "id": "3YDBr9IfdMc_"
   },
   "source": [
    "Let us train the model using Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd505d16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "b0d203535ccc4f41b7fb67691facbefb",
      "1c827ad658e04c299d037bc59beebef1",
      "de0f72586c9d4012a88b659c86c81cbf",
      "30f2e55aef0343389c4ca896954a65d7",
      "f283f9347e664f05994b4594b090fd60",
      "d8276173d44f4f9e93b16416be64e56a",
      "3cf1612457ef404fb490bfcef697ddfa",
      "d622a5a1246b494cae59fa22e43290fb",
      "6e6844492ccb4ac2a79b3045df5a94ad",
      "eb55b760369d4215885394806b05d3c3",
      "c56b3c190ee54116bb99ddbe924007d8"
     ]
    },
    "id": "0CnMaY-iBNot",
    "outputId": "3e5b7d38-de81-46e5-b1ff-1507ba9f456b"
   },
   "outputs": [],
   "source": [
    "sgmodel = SkipGramNegativeSampling(n_nodes=len(G), dim=16)\n",
    "epoch_loss = []\n",
    "opt = Adam(sgmodel.parameters(), lr=0.1)\n",
    "dloader = DataLoader(dataset, batch_size=len(G))\n",
    "for epoch in trange(50):\n",
    "    for start_nodes, pos_context, neg_context in dloader:\n",
    "        loss = sgmodel(start_nodes, pos_context, neg_context).sum(dim=1).mean()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    epoch_loss.append(loss.item())\n",
    "plt.plot(epoch_loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd618bc",
   "metadata": {
    "id": "fOEAkiCUUfsu"
   },
   "source": [
    "We evaluate the model by mutual information between ground truth labels and cluster indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d4f1c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1mdPsAiWFZ0Y",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95d47fc2fc4c52f43987f446abb71cb2",
     "grade": true,
     "grade_id": "cell-1685a473a18d47f8",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    emb = sgmodel.start_node_emb(torch.arange(len(G)))\n",
    "_, pred_labels, _ = k_means(emb, n_clusters=8)\n",
    "mi = mutual_info_score(labels, pred_labels)\n",
    "assert mi > 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e262b",
   "metadata": {
    "id": "As_bLu2mVGae"
   },
   "source": [
    "Let us plot the t-SNE visualization of node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000a3c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "BrZKP5i3UzFs",
    "outputId": "b9675b64-eb20-43cf-f7ca-c0ed59fa5124"
   },
   "outputs": [],
   "source": [
    "decomposition = TSNE(n_components=2)\n",
    "xy_emb = decomposition.fit_transform(emb)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "scatter = plt.scatter(xy_emb[:, 0], xy_emb[:, 1], c=labels, s=10, cmap=plt.cm.Set2)\n",
    "\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=unique)\n",
    "plt.title(f'MI: {mi:.4f}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee2414",
   "metadata": {},
   "source": [
    "### Task 2. Node2Vec (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977516e",
   "metadata": {
    "id": "5q-lgag_YnQ3"
   },
   "source": [
    "In this task, we will consider Node2Vec embedding algorithm. In Node2Vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. It is similar to DeepWalk, but uses *biased random walk procedure* which efficiently explores diverse neighborhoods. There are two parameters:\n",
    "\n",
    "* Return parameter $p$ controls the likelihood of immediately revisiting a node in the walk. Setting it to a high value ensures that we are less likely to sample an already-visited node in the following two steps.\n",
    "\n",
    "* In-out parameter $q$ allows the search to differentiate between “inward” and “outward” nodes. If $q > 1$, the random walk is biased towards nodes close to previous node. In contrast, if $q < 1$, the walk is more inclined to visit nodes which are further away from the previous node.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/netspractice/network-science/main/images/biased_random_walk.png' width=300>\n",
    "\n",
    "Consider that we just moved from the node $t$ to $v$ and now we want to decide on the next step so it evaluates the transition probabilities on edges ($v$, $x$) leading from $v$. Then the *unnormalized* probability is\n",
    "\n",
    "$$\\alpha = \\begin{cases}\n",
    "\\frac{1}{p} &  \\text{ if } d_{tx} = 0\\\\\n",
    "1 & \\text{ if } d_{tx} = 1\\\\\n",
    "\\frac{1}{q} & \\text{ if } d_{tx} = 2\\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "where $d_{tx}$ is the shortest path distance between nodes $t$ and $x$. To compute the true probability, we need to normalize values so that the sum is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e05c1",
   "metadata": {
    "id": "9LFfr6fy18Gb"
   },
   "source": [
    "Write a function `biased_random_walk` that takes a graph, node for which we start random walk, length of walk, parameters `p` and `q` and returns a list with random walks.\n",
    "\n",
    "*Hint: do not use `nx.shortest_path` to calcule shortest paths, it is too expensive. Look at the image above — we can explicitly calculate probabilities for all neighbors of $v$ using neighborhood of $t$*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43c527",
   "metadata": {
    "deletable": false,
    "id": "HGXAsOHw-aUV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "248810a536b6d7a59e0b93a8937cf7a8",
     "grade": false,
     "grade_id": "cell-982226ce9aa30f91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def biased_random_walk(G, node, length, p, q):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7199aa9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "uzi9dGUUcYMh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1bac44bda5b526611348dfdcc645775",
     "grade": true,
     "grade_id": "cell-0404594e2e4226e7",
     "locked": true,
     "points": 1.67,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rwalks = biased_random_walk(G, 0, 10, 0.1, 0.5)\n",
    "assert len(rwalks) == 10\n",
    "rwalks = biased_random_walk(G, node=0, length=4, p=0.001, q=1000)\n",
    "assert rwalks[0] == rwalks[2]\n",
    "assert rwalks[1] == rwalks[3]\n",
    "rwalks = biased_random_walk(G, node=0, length=4, p=1000, q=0.001)\n",
    "assert len(set(rwalks)) >= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42172550",
   "metadata": {
    "id": "LGqNp_axcyFk"
   },
   "source": [
    "Let us generate biased random walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fedad4",
   "metadata": {
    "id": "cmys-WiMGIAz"
   },
   "outputs": [],
   "source": [
    "def sample_biased_random_walks(G, walks_per_node, length, p, q):\n",
    "    walks = []\n",
    "    for node in tqdm(G.nodes, leave=False, desc='Sampling biased random walks'):\n",
    "        for _ in range(walks_per_node):\n",
    "            walk_from_node = biased_random_walk(G, node, length, p, q)\n",
    "            walks.append(walk_from_node)\n",
    "    return np.array(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1baffc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142,
     "referenced_widgets": [
      "cdf30dfa2936467b807ed565733c1921",
      "a5bcacf8222c44faa916edc17f0a1192",
      "6042e824f60d4eab84af0f54b22be1f1",
      "fd5b890b765440538c08f80a99da2155",
      "d49c98f782bd4c79a2424303a3dc0c00",
      "e466c6e63edd43f5a615be8742907054",
      "5aa483f387d347c09d05904a8ccc7ac0",
      "cd4342fc551d4e4fb7aef40b5c2b6ec3",
      "bd3ebfe59de94b18be81439cf63fd9c3",
      "3dddb00aca4347c4a20f2cc5fa58e6b0",
      "81f258b6d3034bf28c7e12fdc314bcb5"
     ]
    },
    "id": "z5GQKyl3GXEy",
    "outputId": "852e0c93-1615-464e-82ad-d0ebb0f46d7c"
   },
   "outputs": [],
   "source": [
    "walks_per_node = 5\n",
    "length = 5\n",
    "rwalks = sample_biased_random_walks(G, walks_per_node, length, p=0.25, q=0.25)\n",
    "rwalks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb66eeb",
   "metadata": {
    "id": "MhZic6vYQbs3"
   },
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97980329",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297,
     "referenced_widgets": [
      "914a2510a07e4004b13764468819c080",
      "c2e03743985842eb80d5a2442bf75164",
      "a9b7867beb84430db0f2552555e80b43",
      "270162e6b6a84169b9cd640027b45efa",
      "f7a84d90f27c497a8d5c75710d27402b",
      "b6d3f3e387464b50bc6037efbfb7e8d3",
      "c90a1ed5bf53491f9cddf3ffec0b6ae9",
      "2fc47ae41520477182d42c42b453e192",
      "1b15e7e2ce7d4331adc7730e2c9145a8",
      "359ffbde40634781bd831aee0ca559e9",
      "bcffc8aad49949b89d0e708dc69b72dc"
     ]
    },
    "id": "EQnnsFnwGlGz",
    "outputId": "47a47314-9cc2-448e-92a9-9a4a6b867d94"
   },
   "outputs": [],
   "source": [
    "e_loss = []\n",
    "dataset = NodeContextDataset(rwalks, len(G), n_neg=5)\n",
    "dloader = DataLoader(dataset, batch_size=len(G))\n",
    "sgmodel = SkipGramNegativeSampling(n_nodes=len(G), dim=16)\n",
    "opt = Adam(sgmodel.parameters(), lr=0.1)\n",
    "for e in trange(50):\n",
    "    for start_nodes, pos_context, neg_context in dloader:\n",
    "        loss = sgmodel(start_nodes, pos_context, neg_context).sum(dim=1).mean()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    e_loss.append(loss.item())\n",
    "plt.plot(e_loss);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c3463",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MUkb4k-mdsj2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a0432f6879bd47681e9f9c94c31ef29",
     "grade": true,
     "grade_id": "cell-d1d23ef4a88759f7",
     "locked": true,
     "points": 1.67,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    emb = sgmodel.start_node_emb(torch.arange(len(G)))\n",
    "_, pred_labels, _ = k_means(emb, n_clusters=8)\n",
    "mi = mutual_info_score(labels, pred_labels)\n",
    "assert mi > 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8af3a",
   "metadata": {
    "id": "3J8GA322eAtB"
   },
   "source": [
    "Find the best $p$ and $q$. Write a function `grid_search_pq` that takes a graph, node labels and returns the best $p$ and $q$ by grid search in $\\{0.01, 0.2, 1, 2, 8\\}$. Sample biased random walks with 5 walks per node and the length 5. Evaluate the model by mutual information score between ground truth labels and k-means with 8 clusters. To pass time limits, calculate the best `p` and `q` and then rewrite the function as\n",
    "\n",
    "```python\n",
    "def grid_search_pq(graph):\n",
    "    return best_p, best_q\n",
    "    # your grid search implementation ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f554d",
   "metadata": {
    "deletable": false,
    "id": "drn8aJkje0D1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2381e148a50dffea83ac5792805d7c31",
     "grade": false,
     "grade_id": "cell-63bf0f1902240663",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def grid_search_pq(G, labels):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9757026",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "425242b29e7f447dabfa9c485ed79ae0",
      "f5407390b4d542f89e20d9d0ef283f81",
      "16ddafa3b1444ab588aae9b2c60a5b9f",
      "4c30bbca485c410eb1f9f47f601761d4",
      "16826c81b2214152ab4c6e1c08384bf3",
      "493277c7e57c44c89218572563b0b163",
      "96e7b0f031ee42fa8e82e379520bf485",
      "69fec3b362de42eca1f1995cca3582d6",
      "d1a021c04e824783b170e6308d364b63",
      "dda702789d244845a51cc77cc548ae4b",
      "0b4526e7de6a4370b2e6dd46210b01f4",
      "c43fa70121f9421dad2ccd42a68634dd",
      "df43e816b3ec4793b507a1506cd027eb",
      "5a7cc0fc092d47d085e5226139f57c55",
      "87b007410dc24c42ac6beb66423fd340",
      "7e9d3438ae3949baa29f0349ca859661",
      "13d4f9f6410a40aeba8d49e11ff5f8ba",
      "f0428256bacd42a4af9207128268844e",
      "80b0a08ffb6c47e898224f6e1bf65672",
      "52bfec89b8e24cd58213d5a3370f3dc6",
      "15c83946d3324f4eb84419a6b7e7c352",
      "6876ce2af20f4477b3f4093579456d52"
     ]
    },
    "deletable": false,
    "editable": false,
    "id": "igTGn7GALOJN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f8a745a85dfd5589db9e9f9a05c9e68c",
     "grade": true,
     "grade_id": "cell-6102dd78a7156238",
     "locked": true,
     "points": 1.6600000000000001,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "2ac286aa-67c8-43ee-ff8e-fff6ba43faef"
   },
   "outputs": [],
   "source": [
    "best_p, best_q = grid_search_pq(G, labels)\n",
    "rwalks = sample_biased_random_walks(G, 5, 5, best_p, best_q)\n",
    "dataset = NodeContextDataset(rwalks, len(G), n_neg=5)\n",
    "dloader = DataLoader(dataset, batch_size=len(G))\n",
    "sgmodel = SkipGramNegativeSampling(n_nodes=len(G), dim=16)\n",
    "opt = Adam(sgmodel.parameters(), lr=0.1)\n",
    "dloader = DataLoader(dataset, batch_size=len(G))\n",
    "for epoch in trange(50):\n",
    "    for start_nodes, pos_context, neg_context in dloader:\n",
    "        loss = sgmodel(start_nodes, pos_context, neg_context).sum(dim=1).mean()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "with torch.no_grad():\n",
    "    emb = sgmodel.start_node_emb(torch.arange(len(G)))\n",
    "_, pred_labels, _ = k_means(emb, n_clusters=8)\n",
    "mi = mutual_info_score(labels, pred_labels)\n",
    "assert mi > 0.21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c123c2",
   "metadata": {
    "id": "4diPYQKCMdoT"
   },
   "source": [
    "Plot t-SNE visualization of node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0f77f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "qkzOkF3NGzbR",
    "outputId": "36fc554c-d7f8-488c-8e09-c964dc16b540"
   },
   "outputs": [],
   "source": [
    "decomposition = TSNE(n_components=2)\n",
    "xy_emb = decomposition.fit_transform(emb)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "scatter = plt.scatter(xy_emb[:, 0], xy_emb[:, 1], c=labels, s=10, cmap=plt.cm.Set2)\n",
    "\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=unique)\n",
    "plt.title(f'MI: {mi:.4f}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a894e",
   "metadata": {},
   "source": [
    "### Task 3. GraRep (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06abb4b8",
   "metadata": {
    "id": "aviJdvivWW6D"
   },
   "source": [
    "The idea behind GraRep is to account for multiscale relationships between nodes. For example,a student can have 1-hop neighborhood of friends, 2-hop neighborhood of classmates, 3-hop neighborhood of society and so on.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/netspractice/network-science/main/images/multiscale_relationships.png\" width=350>\n",
    "\n",
    "Unlike DeepWalk, GraRep defines different objective functions for capturing the different $k$-step local relational information by manipulating transition matrices in the $k$-th powers defined over the graph. Recall that the transition matrix is $P = D^{-1}A$ where $D$ is a degree matrix. $P_{ij}$ refers to a probability to move from the node $i$ to the node $j$ in one step of a random walk. Therefore, $P^k_{ij}$ is a probability to move from the node $i$ to the node $j$ in $k$ steps of a random walk. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bafb7ea",
   "metadata": {
    "id": "vdylqNJVreik"
   },
   "source": [
    "Write a function `csr_transition_matrix` that takes a graph and returns a transition matrix. To save memory and speed up the following calculation of powers, convert transition matrix to sparse format by `scipy.sparse.csr_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b759a",
   "metadata": {
    "deletable": false,
    "id": "ijUKHWFDLKUc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bec7a132a8e91292a33f9ce803d9e648",
     "grade": false,
     "grade_id": "cell-f0ec11b1c4da2c21",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def csr_transition_matrix(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9eb05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "414367d3e3ea4d608a89daa8c46d77ab",
      "64425f50f6c64e71b36a84d9dc00b296",
      "81dd316a820a4dd98f5770241b14fc56",
      "4b9a2e5ed5ca4a9aaac9f7ff44a7c84b",
      "468e0e0c7e5b4b24a7f180e9b177d377",
      "c0961ed13ab549719b896b6e19885e4e",
      "e21f49b6078648ad9d58fb962700db3d",
      "b551e27a37784378aab301cd6b481b3a",
      "10c0fb90ee814efc8180bb7a48e7305d",
      "7f0d551f9ac646d987cb2f198fce7c79",
      "1ee478f0cef24e9a8003e14f48efb787"
     ]
    },
    "deletable": false,
    "editable": false,
    "id": "LKqHuKwhLvI6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb3a0c48ae5562e62fb65b6a8f584440",
     "grade": true,
     "grade_id": "cell-2d2f99d8bac11893",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "8651634b-040b-45f9-df47-88f2cdb64dad"
   },
   "outputs": [],
   "source": [
    "P = csr_transition_matrix(G)\n",
    "assert type(P) == csr_matrix\n",
    "assert P.shape == (len(G), len(G))\n",
    "assert round(P[3, 9], 4) == 0.0417"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69317582",
   "metadata": {
    "id": "NAQLGKBAH8tf"
   },
   "source": [
    "Similar to DeepWalk, there are two types of embeddings:\n",
    "* $v_i$ is a vector that represents the start node $i$\n",
    "* $u_j$ is a vector that represents the context node $j$\n",
    "\n",
    "Our objective aims to maximize: 1) the probability that these pairs come from the graph, and 2) the probability that all other pairs do not come from the graph (negative samples). The objective function for nodes $i, j$ in the transition matrix of the power $k$ is\n",
    "\n",
    "$$\\mathcal L^k_{ij} = P^k_{ij}\\log \\sigma(v_i^\\top u_j) + \\frac{\\lambda}{|V|}\\sum_{t=1}^{|V|}P^k_{tj}\\log \\sigma(-v_t^\\top u_j)$$\n",
    "\n",
    "where $\\lambda$ is the hyperparameter indicating the number of negative samples. Optimizing this objective makes observed pairs $(i, j)$ have similar embeddings, while scattering unobserved pairs $(t, j)$. Substitution $v_i^\\top u_j = X_{ij}$ and setting $\\frac{\\partial \\mathcal L_{ij}}{ \\partial X_{ij}} = 0$ yields\n",
    "\n",
    "$$v_i^\\top u_j = X_{ij}^k = \\log \\frac{P^k_{ij}}{\\sum_{t=1}^{|V|}P^k_{tj}} - \\log\\frac{\\lambda}{|V|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae71ba7",
   "metadata": {
    "id": "X7bwqmWGs-QC"
   },
   "source": [
    "Let us call $X^k$ log probabilistic matrix. Write a function `log_probabilistic_matrix` that takes a transition matrix, hyperparameter $\\lambda$ and returns a log probabilistic matrix.\n",
    "\n",
    "_Remark: to prevent $-\\infty$ in log, add $\\varepsilon=1^{-6}$ as follows `np.log(x + 1e-6)`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c98c7",
   "metadata": {
    "deletable": false,
    "id": "XjVAyoUiMq_8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63684003d32189034bf77a52da99cd2b",
     "grade": false,
     "grade_id": "cell-c949fe784127c31a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_probabilistic_matrix(P, lambd):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab24185",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "eaf532492cc2425db11cd67e6ec23ebf",
      "b77c5b29a7104db48413aad1c50b5aae",
      "7b1e5ada2ca24915a1619821e94cce93",
      "78bafc3e493c41f6ae29ede92e1a05da",
      "681af90fa8054b58a1940341f6d801fa",
      "466f48d279ad420aa72838443116fad6",
      "1a8116ec5bc84bb49410fa2e86c16f2f",
      "4646ac45ffcc48f29e6b5660d78d855d",
      "9735cb7492e74a6f97966088ca84a665",
      "6f934c75474a45fa8ba082cadd70015e",
      "d0ecb092472447e18eeb6567d200ba52"
     ]
    },
    "deletable": false,
    "editable": false,
    "id": "KTl_DISFt8mA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de5b271579f12414c936ca423963efbc",
     "grade": true,
     "grade_id": "cell-624f6d1384718d6f",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ec96a030-10f9-4591-adc7-254174c0227b"
   },
   "outputs": [],
   "source": [
    "X = log_probabilistic_matrix(P, lambd=5)\n",
    "assert type(X) == np.matrix\n",
    "assert X.shape == (len(G), len(G))\n",
    "assert round(X[3, 9], 4) == 3.182"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6a2cd",
   "metadata": {
    "id": "y56r1-evIBAJ"
   },
   "source": [
    "The log probabilistic matrix $X^k$ can be approximated by truncated SVD so that\n",
    "\n",
    "$$X^k \\approx X_d^k = U_d^k \\Sigma_d^k (V_d^k)^\\top$$\n",
    "\n",
    "where $d$ is the number of singular values of truncated SVD. Thus, embeddings of start nodes can be obtained by \n",
    "\n",
    "$$v_i = \\left[U_d^k \\sqrt{\\Sigma_d^k}\\right]_i$$ \n",
    "\n",
    "and embeddings of context nodes by \n",
    "\n",
    "$$u_j = \\left[\\sqrt{\\Sigma_d^k} (V_d^k)^\\top\\right]_j$$ \n",
    "\n",
    "_Remark: the power 1/2 makes SVD symmetric. It is empirically shown that the symmetric SVD is better for social graphs and makes embeddings more \"similar\" to corresponding embeddings of SkipGram with negative sampling in a sence of some matrix properties._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f56d49",
   "metadata": {
    "id": "M5gDGuACuy-5"
   },
   "source": [
    "Write a function `svd_emb` that takes a log probabilistic matrix, number of dimensions (number of largest singular values) in truncated SVD and returns embeddings of start nodes.\n",
    "\n",
    "_Hint: use `scipy.sparse.linalg.svds` to calculate truncated SVD for a given number of singular values._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8394a5",
   "metadata": {
    "deletable": false,
    "id": "S9yoD3FxOXbw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64aa1dc62ca5b5035ec1eedfc7372ab7",
     "grade": false,
     "grade_id": "cell-683cb8f26df5fd3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def svd_emb(X, dim):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9113c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "761767a99fed4419cd86c29a943533c2",
     "grade": true,
     "grade_id": "cell-426bb9037fe96aba",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_emb = svd_emb(X, dim=4)\n",
    "assert type(_emb) == np.ndarray\n",
    "assert _emb.shape == (3873, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0613af",
   "metadata": {
    "id": "DMgCQ_9GxjKg"
   },
   "source": [
    "\n",
    "The resulting node embeddings are concatenated from the log probabilistic matrices $X, X^2, ..., X^k$.\n",
    "\n",
    "In `grarep_emb`, we calculate powers of transition matrix $P, P^2, \\dots, P^k$, calculate and concatenate embeddings of start nodes, then we compress them to the original number of dimensions by PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e417fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08744ba53988cb545f953cce607f67c6",
     "grade": false,
     "grade_id": "cell-fe1d6156e8d730ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def grarep_emb(G, dim, k, lambd):\n",
    "    emb = []\n",
    "    P_1 = csr_transition_matrix(G)\n",
    "    P = P_1.copy()\n",
    "    for i in trange(k):\n",
    "        X = log_probabilistic_matrix(P, lambd=lambd)\n",
    "        _emb = svd_emb(X, dim=dim)\n",
    "        emb.append(_emb)\n",
    "        if i == (k - 1):\n",
    "            continue\n",
    "        P = P @ P_1\n",
    "    emb = PCA(n_components=dim).fit_transform(np.concatenate(emb, axis=1))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758247ec",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model by mutual information between ground truth labels and cluster indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a7e4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "9313e90778c04cb9be8038087f8de9e4",
      "742d688b293c4523bda4abd2d3d9d203",
      "2b20519ff4354656942d63d067c61740",
      "6f5f386cc8ce4b70aa5b3a2202cdfb74",
      "5c3c0e1550544177bd063261ffe8ca12",
      "0d9b6e664d9c4a1bbe20eb7fdf16da2f",
      "092ec69a30964666bd92896978c0c976",
      "4234c3dd32264885ba8b7e7724a2235a",
      "4104856a8c704b85be422c3baae777ed",
      "7bf3033f9a50479289d5980a1ff22cd6",
      "b771aabb1ac74a7fbdf94c8f0bd796b9"
     ]
    },
    "deletable": false,
    "editable": false,
    "id": "0NvbTouIFSm7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8701fbbd377660f4857cacc951a71a6",
     "grade": true,
     "grade_id": "cell-a016b73d556e34c9",
     "locked": true,
     "points": 1.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "b8d7c630-5f5d-4439-acfa-bdb4b06be7c7"
   },
   "outputs": [],
   "source": [
    "emb = grarep_emb(G, dim=16, k=4, lambd=5)\n",
    "assert emb.shape == (len(G), 16)\n",
    "_, pred_labels, _ = k_means(emb, n_clusters=8)\n",
    "mi = mutual_info_score(labels, pred_labels)\n",
    "assert mi > 0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee54a6e",
   "metadata": {
    "id": "VkLVoqDV0L93"
   },
   "source": [
    "Plot t-SNE visualization of node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe58e9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "ur-bWmtED-DE",
    "outputId": "87a5956c-dbbf-42fe-c351-123a04d6f41a"
   },
   "outputs": [],
   "source": [
    "decomposition = TSNE(n_components=2)\n",
    "xy_emb = decomposition.fit_transform(emb)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "scatter = plt.scatter(xy_emb[:, 0], xy_emb[:, 1], c=labels, s=10, cmap=plt.cm.Set2)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=unique)\n",
    "plt.title(f'MI: {mi:.4f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5afd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
