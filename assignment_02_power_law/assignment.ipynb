{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b3716a",
   "metadata": {},
   "source": [
    "# Assignment — Power law and scale-free networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from zlib import adler32\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e869c3e",
   "metadata": {},
   "source": [
    "### Task 1. Graphs by degree distribution (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec3e93",
   "metadata": {},
   "source": [
    "In this task, we will try to guess a graph by its degree distribution.\n",
    "\n",
    "__Graph A__ is described by the histogram `[0, 2, 10]` — 0 nodes with degree 0, 2 nodes with degree 1, 10 nodes with degree 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1282fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_a = [0, 2, 10]\n",
    "plt.bar(range(len(dens_a)), dens_a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802aa30",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7726ebdf8814362b9595c84fe0221e09",
     "grade": false,
     "grade_id": "cell-4308485bfb1bf30e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_graph_a() -> nx.Graph:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbf0df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0a57f4933c3d7409a8822292bff6c0b",
     "grade": true,
     "grade_id": "cell-226da2d721eaace4",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = generate_graph_a()\n",
    "assert nx.degree_histogram(G) == dens_a\n",
    "assert nx.is_connected(G)\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e54bbe",
   "metadata": {},
   "source": [
    "__Graph B__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f53ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_b = [0, 0, 10]\n",
    "plt.bar(range(len(dens_b)), dens_b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb0c6a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41e7af615198bd34567381ea1b34f56c",
     "grade": false,
     "grade_id": "cell-55d7cfacd5c8d553",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_graph_b() -> nx.Graph:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2e464",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17a01a7b79ffd6127bc1d861c15eec61",
     "grade": true,
     "grade_id": "cell-11bb8205ad27326a",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = generate_graph_b()\n",
    "assert nx.degree_histogram(G) == dens_b\n",
    "assert nx.is_connected(G)\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85335733",
   "metadata": {},
   "source": [
    "__Graph C__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f97242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_c = [0, 0, 0, 0, 5]\n",
    "plt.bar(range(len(dens_c)), dens_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b1d82",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dac931bc16a78ae011fdaab8f99a54ca",
     "grade": false,
     "grade_id": "cell-6ad0ea3f81976162",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_graph_c() -> nx.Graph:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62ec46",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e757472a112c724d13e0fe548746c245",
     "grade": true,
     "grade_id": "cell-508d2e23c067c4d2",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = generate_graph_c()\n",
    "assert nx.degree_histogram(G) == dens_c\n",
    "assert nx.is_connected(G)\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d53560a",
   "metadata": {},
   "source": [
    "__Graph D__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dens_d = [0, 5, 0, 0, 0, 1]\n",
    "plt.bar(range(len(dens_d)), dens_d);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75bdbb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1ab3b74f2b7a677c3844675c785ef5a",
     "grade": false,
     "grade_id": "cell-2a6c0c0fe4dda491",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_graph_d() -> nx.Graph:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ab939",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2017a6038396ef2a945258eca96539c",
     "grade": true,
     "grade_id": "cell-c9c34144467f9031",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = generate_graph_d()\n",
    "assert nx.degree_histogram(G) == dens_d\n",
    "assert nx.is_connected(G)\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a54b6e",
   "metadata": {},
   "source": [
    "### Task 2. Network degree CDF (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496597ee",
   "metadata": {},
   "source": [
    "In this task we will estimate CDF of degree distribution of a given graph. Firstly, let us download the Game of Thrones relationships dataset and create a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"https://raw.githubusercontent.com/network-science-course/network-science-course/main/datasets/game_of_thrones_relationships.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193366bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.from_pandas_edgelist(raw_data, source=\"character1\", target=\"character2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbc4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(g, node_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360f73bf",
   "metadata": {},
   "source": [
    "In the social network analysis, we will often consider the largest connected component only. Before estimation of CDF, we need to remove all connected components except of the largest one.\n",
    "\n",
    "_Hint: use `nx.connected_components` to get a list of nodes for each connected component._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c313f81",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07e8207f2a0510ee621508841df6acd0",
     "grade": false,
     "grade_id": "cell-37477b43188105f5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def select_gygantic_component(g: nx.Graph) -> nx.Graph:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c8148",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e81175c27872554d5ea17feac137c6d",
     "grade": true,
     "grade_id": "cell-00509dc9b42f24ea",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "gg = select_gygantic_component(g)\n",
    "assert gg.number_of_edges() == 49\n",
    "assert gg.number_of_nodes() == 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(gg, node_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170801e5",
   "metadata": {},
   "source": [
    "Now we can calculate an empirical CDF for a given graph. Recall a formal definition of CDF\n",
    "\n",
    "$$F_X(x) = P(X \\leq x)$$\n",
    "\n",
    "And in empirical CDF, we estimate probability by share of nodes.\n",
    "\n",
    "Write a method `empirical_cdf` that takes a graph and returns a np.array of probabilities. The first element is related to the node degree 0, the second — the node degree 1 and so on. The method should be able to group degrees occurence into equaly distributed bins. \n",
    "\n",
    "_Hint: use `nx.degee_histogram` to return a degree histogram — a list of numbers of nodes for each degree._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree_histogram(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad662c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc0bf47192b76ea6bcdde2ddec48367f",
     "grade": false,
     "grade_id": "cell-cbb478364b51233f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def empirical_cdf(g: nx.Graph) -> List[float]:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5edd5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b375df2a4660021348fd3994182b9c09",
     "grade": true,
     "grade_id": "cell-a1fd6b06aff25d78",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ecdf = empirical_cdf(gg)\n",
    "assert ecdf[0] == 0\n",
    "assert ecdf[-1] == 1\n",
    "assert np.all(ecdf[:-1] <= ecdf[1:])\n",
    "assert adler32(str(empirical_cdf(gg).round(4).sum()).encode()) == 70123823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ecdf)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('probability')\n",
    "plt.title('Empirical CDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34130986",
   "metadata": {},
   "source": [
    "### Task 3. Power law CDF (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e11be2",
   "metadata": {},
   "source": [
    "Scale-free network has a Power law degree distribution. Let us take a closer look at this distribution. The PDF of the Power law is \n",
    "\n",
    "$$ p(x) = Cx^{-\\alpha},$$ \n",
    "\n",
    "where $C$ is a normalization constant \n",
    "\n",
    "$$C = \\frac{\\alpha - 1}{x_{\\text{min}}^{-\\alpha + 1}}$$ \n",
    "\n",
    "and $\\alpha>1$ is called an exponent of the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law_pdf(x, alpha=3.5, x_min=1):\n",
    "    C = (alpha - 1) / x_min ** (1 - alpha)\n",
    "    return C * x ** (-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31727dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_space = np.linspace(1, 10, 100)\n",
    "plt.plot(x_space, power_law_pdf(x_space))\n",
    "plt.title('Power Law PDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d936f7",
   "metadata": {},
   "source": [
    "Let us generate observations from a Power Law RV. The first step is to derive CDF of Powel law: $F(x) = P(X \\leq x)$\n",
    "\n",
    "$$F(x) = 1 - \\int_{x}^\\infty p(t) dt.$$\n",
    "\n",
    "Take the integral, derive CDF analytically and then write a function `power_law_cdf` with parameters `x`, `alpha` and `x_min`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983c2dd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfa3158ba5ebe1454116372e3a44aec9",
     "grade": false,
     "grade_id": "cell-f682e125051975d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def power_law_cdf(x, alpha=3.5, x_min=1):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198c4e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5026b776b780dfcbef35878e3db5366",
     "grade": true,
     "grade_id": "cell-87d0428f480773c4",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert power_law_cdf(2, 2, 1) == 0.5\n",
    "assert power_law_cdf(10, 2, 1) == 0.9\n",
    "assert adler32(str(power_law_cdf(2, 3, 1)).encode()) == 32571595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_space = np.linspace(1, 10, 100)\n",
    "plt.plot(x_space, power_law_cdf(x_space))\n",
    "plt.title('Power Law CDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684b77e",
   "metadata": {},
   "source": [
    "### Task 4. Power law PPF (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9792a",
   "metadata": {},
   "source": [
    "Let $X \\sim \\text{Power law}$. Next, define a random variable $R$, s.t. $R = F(X)$, so $R$ will be uniformly distributed on interval [0, 1] ([proof](https://en.wikipedia.org/wiki/Probability_integral_transform#Proof)). Good thing here is that we easily can generate uniformly distributed pseudorandom numbers and then transform them into Power Law. Let us find an expression for $x = F^{-1}(r)$, where $r$ is an observation from uniform distrubution on interval [0, 1]. \n",
    "\n",
    "Find an analytical form of $F^{-1}(r)$ and write a function `power_law_ppf` (percent point function, also known as a quantile) with parameters `r`, `alpha` and `x_min`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97f61a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be67ee873cb3bf60c2e62921b187b228",
     "grade": false,
     "grade_id": "cell-63a819b2bc8441f1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def power_law_ppf(r, alpha=3.5, x_min=1):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d63ada",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e6ca2ea8df06ab41316d28339f43b53",
     "grade": true,
     "grade_id": "cell-0b447767612a3798",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(power_law_ppf(0.5, 2, 1), 2) == 2\n",
    "assert round(power_law_ppf(0.9, 2, 1), 2) == 10\n",
    "assert adler32(str(round(power_law_ppf(0.96, 3, 1), 2)).encode()) == 19792020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_space = np.linspace(0, 0.999, 100)\n",
    "plt.plot(x_space, power_law_ppf(x_space))\n",
    "plt.title('Power Law PPF');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87684959",
   "metadata": {},
   "source": [
    "Finally, we can generate observation from Power law distribution as follows:\n",
    "1. Generate observation from uniform distribution on interval [0, 1]\n",
    "2. Calculate PPF value of given observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c68888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law_generate(n, alpha=3.5, x_min=1, random_seed=1):\n",
    "    np.random.seed(random_seed)\n",
    "    uni_sample = np.random.uniform(0, 0.999, n)\n",
    "    return power_law_ppf(uni_sample, alpha, x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f52f7",
   "metadata": {},
   "source": [
    "Look at the histogram of the generated sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3.5\n",
    "x_min = 1\n",
    "x_train = power_law_generate(1000, alpha, x_min)\n",
    "x_space = np.linspace(1, 15, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bin_edges = np.histogram(x_train, bins=200, density=True)\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "plt.scatter(bin_centers[hist > 0], hist[hist > 0], s=10)\n",
    "plt.plot(x_space, power_law_pdf(x_space, alpha, x_min), \n",
    "         label='Theoretical PDF', c='tab:orange')\n",
    "plt.legend()\n",
    "plt.xlim(1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14e5bc",
   "metadata": {},
   "source": [
    "And here is the same histogram in log-log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bin_edges = np.histogram(x_train, bins=200, density=True)\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "plt.scatter(bin_centers, hist, s=10)\n",
    "plt.plot(x_space, power_law_pdf(x_space, alpha, x_min), \n",
    "         label='Theoretical PDF', c='tab:orange')\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(1, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd66f7e",
   "metadata": {},
   "source": [
    "### Task 5. Estimation of alpha with linear binning (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d563585",
   "metadata": {},
   "source": [
    "Given observations from the Power Law distribution, try to estimate $\\alpha$. The easiest way is to draw an empirical PDF with linear binning in log-log scale and apply linear regression. By _linear binning_ we mean to keep a bin width is fixed.\n",
    "\n",
    "Write a function `alpha_lin_bins` that takes a train set, number of linear bins and returns an estimated $\\alpha$.\n",
    "\n",
    "_Hints:_\n",
    "* _Take log in both side of $p(x) = Cx^{-\\alpha}$_\n",
    "* _To calculate an empirical PDF, use `np.histogram(x_train, bins=bins, density=True)`_\n",
    "* _To calculate pseudoinverse matrix, use `np.linalg.pinv`_\n",
    "* _Also you can fit `sklearn.linear.LinearRegression`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2dfef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98c4c6ef2ed0c2d94c440d3e8e932b7e",
     "grade": false,
     "grade_id": "cell-c57a5c7c5834b80e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alpha_lin_bins(x_train, bins):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd841f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de1fcde9e88bb74af93932b7dea4402d",
     "grade": true,
     "grade_id": "cell-b9cf21aabb190bd7",
     "locked": true,
     "points": 0.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bins = 100\n",
    "x_train = power_law_generate(1000, x_min=1, alpha=2)\n",
    "assert np.abs(alpha_lin_bins(x_train, bins) - 2) < 0.7\n",
    "x_train = power_law_generate(1000, x_min=1, alpha=3.5)\n",
    "assert np.abs(alpha_lin_bins(x_train, bins) - 3.5) < 0.9\n",
    "x_train = power_law_generate(1000, x_min=1, alpha=10)\n",
    "assert np.abs(alpha_lin_bins(x_train, bins) - 10) < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 1\n",
    "alpha = 3.5\n",
    "bins = 100\n",
    "\n",
    "x_train = power_law_generate(1000, alpha, x_min)\n",
    "hist, bin_edges = np.histogram(x_train, bins=bins, density=True)\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "plt.scatter(bin_centers, hist, s=10)\n",
    "\n",
    "hat_alpha = alpha_lin_bins(x_train, bins)\n",
    "x_space = np.linspace(x_min, x_train.max(), 100)\n",
    "plt.plot(x_space, power_law_pdf(x_space, hat_alpha, x_min), \n",
    "         label='Estimated PDF', c='tab:orange')\n",
    "plt.legend()\n",
    "plt.title('Truth alpha = {:.2f}, estimated alpha = {:.2f}'.format(alpha, hat_alpha))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa92c9",
   "metadata": {},
   "source": [
    "### Task 6. Estimation of alpha with logarithmic binning (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa81ceb",
   "metadata": {},
   "source": [
    "As we see the estimation with linear binning is noticeably inaccurate. For logarithmic binning we let the bin sizes increase with the value, making sure that each bin has a comparable number of observations.\n",
    "\n",
    "Write a function `alpha_log_bins` that takes a train set, number of log bins and returns an estimated $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ddf2c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f20a7d7035785da992e45b13ecfac97b",
     "grade": false,
     "grade_id": "cell-bc1092822f8126d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def alpha_log_bins(x_train, bins):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62331e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69e67e3ca7713364d8f99adf6ea4bb5d",
     "grade": true,
     "grade_id": "cell-1bc5eba53dc73dbd",
     "locked": true,
     "points": 4.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bins = 100\n",
    "x_train = power_law_generate(1000, x_min=1, alpha=2)\n",
    "assert np.abs(alpha_log_bins(x_train, bins) - 2) < 0.2\n",
    "x_train = power_law_generate(1000, x_min=1, alpha=3.5)\n",
    "assert np.abs(alpha_log_bins(x_train, bins) - 3.5) < 0.5\n",
    "x_train = power_law_generate(1000, x_min=1, alpha=10)\n",
    "assert np.abs(alpha_log_bins(x_train, bins) - 10) < 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 1\n",
    "alpha = 3.5\n",
    "bins = 100\n",
    "\n",
    "x_train = power_law_generate(1000, alpha, x_min)\n",
    "binning = np.logspace(np.log10(x_min), np.log10(x_train.max()), bins)\n",
    "hist, bin_edges = np.histogram(x_train, bins=binning, density=True)\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1]) / 2\n",
    "plt.scatter(bin_centers, hist, s=10)\n",
    "\n",
    "hat_alpha = alpha_log_bins(x_train, bins)\n",
    "x_space = np.linspace(x_min, x_train.max(), 100)\n",
    "plt.plot(x_space, power_law_pdf(x_space, hat_alpha, x_min), \n",
    "         label='Estimated PDF', c='tab:orange')\n",
    "plt.legend()\n",
    "plt.title('Truth alpha = {:.2f}, estimated alpha = {:.2f}'.format(alpha, hat_alpha))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d0cda",
   "metadata": {},
   "source": [
    "### Task 7. QQ Plot (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78fb30b",
   "metadata": {},
   "source": [
    "It might be useful to draw a quantile-quantile plot (QQ plot) to compare empirical and theoretical distributions by the eye. Your task here is to generate Power Law observations by given parameters and compare theoretical and empirical quantiles.\n",
    "\n",
    "Write a function `qqplot_data` that takes $\\alpha$, $x_\\min$, number of observations $n$ that will be generated and returns a tuple with two np.arrays: theoretical quantiles and empirical quantiles. Let quantiles be calculated for probabilities 0, 0.01, 0.02, ..., 0.99.\n",
    "\n",
    "_Hint: to calculate an empirical quantile, use `np.quantile`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79552976",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8eec986886f46027e0d0884381921de0",
     "grade": false,
     "grade_id": "cell-7536b41d94152420",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def qqplot_data(alpha, x_min, n):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a9838",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cadf93302d494649d48b907845699beb",
     "grade": true,
     "grade_id": "cell-cee74bedb007dbfa",
     "locked": true,
     "points": 3.0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_min = 1\n",
    "alpha = 3.5\n",
    "\n",
    "theor100, empir100 = qqplot_data(alpha, x_min, 100)\n",
    "theor200, empir200 = qqplot_data(alpha, x_min, 200)\n",
    "theor1000, empir1000 = qqplot_data(alpha, x_min, 1000)\n",
    "assert np.linalg.norm(theor1000 - empir1000) < np.linalg.norm(theor200 - empir200)\n",
    "assert np.linalg.norm(theor200 - empir200) < np.linalg.norm(theor100 - empir100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(theor100, empir100, s=10)\n",
    "plt.plot([1, 7], [1, 7], '--', c='tab:orange')\n",
    "plt.title('QQ plot, N = 100')\n",
    "plt.xlabel('Theoretical distribution')\n",
    "plt.ylabel('Empirical distribution')\n",
    "plt.axis('square')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(theor200, empir200, s=10)\n",
    "plt.plot([1, 7], [1, 7], '--', c='tab:orange')\n",
    "plt.title('QQ plot, N = 200')\n",
    "plt.xlabel('Theoretical distribution')\n",
    "plt.ylabel('Empirical distribution')\n",
    "plt.axis('square')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(theor1000, empir1000, s=10)\n",
    "plt.plot([1, 7], [1, 7], '--', c='tab:orange')\n",
    "plt.title('QQ plot, N = 1000')\n",
    "plt.xlabel('Theoretical distribution')\n",
    "plt.ylabel('Empirical distribution')\n",
    "plt.axis('square');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076c717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
